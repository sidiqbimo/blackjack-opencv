import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.applications import MobileNetV2
from sklearn.model_selection import train_test_split
from sklearn.utils import class_weight
import collections
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

# Define the path to the dataset
dataset_path = "D:\\Programming\\Python\\cardGameProject\\dataset"

# Prepare data and labels
data = []
labels = []
label_dict = {label: idx for idx, label in enumerate(os.listdir(dataset_path))}

# Load and preprocess the images
for label in label_dict:
    label_dir = os.path.join(dataset_path, label)
    if os.path.isdir(label_dir):
        for filename in os.listdir(label_dir):
            img_path = os.path.join(label_dir, filename)
            img = cv2.imread(img_path)
            if img is not None:
                img = cv2.resize(img, (128, 128))  # Resize to a consistent shape
                img = img / 255.0  # Normalize the image
                data.append(img)
                labels.append(label_dict[label])

# Convert data and labels to numpy arrays
data = np.array(data)
labels = np.array(labels)

# Print class distribution
class_counts = collections.Counter(labels)
print("Class Distribution:")
for label_idx, count in class_counts.items():
    label_name = [name for name, idx in label_dict.items() if idx == label_idx][0]
    print(f"Class '{label_name}' ({label_idx}): {count} samples")

# Split data into training and testing sets using stratified split
x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42, stratify=labels)

# Calculate class weights to handle imbalanced dataset
class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)
class_weights = {i: class_weights[i] for i in range(len(class_weights))}

# Data augmentation to improve model generalization
data_augmentation = keras.Sequential([
    layers.RandomFlip("horizontal_and_vertical"),
    layers.RandomRotation(0.2),
    layers.RandomZoom(0.2)
])

# Load the MobileNetV2 pre-trained model
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))
base_model.trainable = False  # Freeze the base model to retain pre-trained weights

# Build a transfer learning model using MobileNetV2 as a base
model = keras.Sequential([
    data_augmentation,  # Add data augmentation as the first layer
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),
    layers.BatchNormalization(),
    layers.Dropout(0.5),
    layers.Dense(len(label_dict), activation='softmax')  # Number of output classes
])

# Compile the model with a more robust optimizer
model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Train the model with more epochs for better learning
history = model.fit(x_train, y_train, epochs=30, validation_split=0.1, batch_size=32, class_weight=class_weights)

# Ensure the model is built by calling it on some data
model.build((None, 128, 128, 3))

# Save the model
model_path = "D:\\Programming\\Python\\cardGameProject\\card_classifier_model.keras"
model.save(model_path)
print(f"Model saved at {model_path}")